{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Classification Hans-on\n",
    "\n",
    "\n",
    "## Hans-on target\n",
    "- This is for beginners of NLP.\n",
    "\n",
    "## Datasets\n",
    "- Cornell MR(movie review) Dataset (https://www.cs.cornell.edu/people/pabo/movie-review-data/)\n",
    "\n",
    "## Implement Models\n",
    "- RNN\n",
    "- LSTM\n",
    "- Bi-LSTM\n",
    "- LSTM with Attention\n",
    "- CNN\n",
    "\n",
    "## References\n",
    "- [Recent Trends in Deep Learning Based Natural Language Processing, 2018](https://arxiv.org/pdf/1708.02709.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hans On\n",
    "\n",
    "## Pre processing\n",
    "- Conell MR data is formmated as sentence and label file.\n",
    "- So we need to convert TSV dataset for training easily.\n",
    "- And also we need to split dataset as `train`, `dev(valid)`, `test` for training.\n",
    "- ref. [preprocessing.py](preprocessing.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class TSVGenerator(object):\n",
    "    def __init__(self, root_dir='data'):\n",
    "        self.root_dir = root_dir\n",
    "        self.phase = ['train', 'dev', 'test']\n",
    "        self.corpus_path = os.path.join(root_dir, \"{}.sen\")\n",
    "        self.label_path = os.path.join(root_dir, \"{}.lab\")\n",
    "\n",
    "    def __call__(self, phase):\n",
    "        assert phase in self.phase, 'Unable phase'\n",
    "\n",
    "        corpus_path = self.corpus_path.format(phase)\n",
    "        label_path = self.label_path.format(phase)\n",
    "\n",
    "        corpus = [line.replace('\\n', '').strip()\n",
    "                  for line in open(corpus_path, 'r').readlines()]\n",
    "        label = [line.replace('\\n', '').strip()\n",
    "                 for line in open(label_path, 'r').readlines()]\n",
    "\n",
    "        with open(os.path.join(self.root_dir, f'{phase}.tsv'), 'w') as f:\n",
    "            for sen, lab in zip(corpus, label):\n",
    "                f.write('{}\\t{}\\n'.format(sen, lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TSVGenerator()\n",
    "target = ['train', 'dev', 'test']\n",
    "for val in target:\n",
    "    generator(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader\n",
    "- After converting Conell MR dataset to TSV format, now we need to implement dataset loader for training.\n",
    "- In hands-on we use the torchtext library(https://pytorch.org/text/stable/index.html).\n",
    "- ref. [dataset.py](dataset.py)\n",
    "\n",
    "### Prequisite\n",
    "- You need to install spacy lauguage first\n",
    "``` bash\n",
    "python -m spacy download en\n",
    "python -m spacy download en_core_web_md\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from en-core-web-sm==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (65.6.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (6.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.65.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (23.0)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.28.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.15)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl#egg=en_core_web_md==3.0.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-md==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl (47.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from en-core-web-md==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.17)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.12)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.28.2)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (65.6.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.24.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.65.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.1.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.26.15)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torchtext.data import Field, LabelField, TabularDataset, Iterator\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "\n",
    "class MyDataset(object):\n",
    "\n",
    "    def __init__(self, root_dir='data', batch_size=64, use_vector=True, pdevice = 'cpu'):\n",
    "        self.TEXT = Field(sequential=True, use_vocab=True, tokenizer_language='en_core_web_sm',\n",
    "                          tokenize='spacy', lower=True, batch_first=True)\n",
    "        self.LABEL = LabelField(dtype=torch.float)\n",
    "        vectors = Vectors(name='mr_vocab.txt', cache='./')\n",
    "        dataset_path = os.path.join(root_dir, '{}.tsv')\n",
    "        self.dataset = {}\n",
    "        self.dataloader = {}\n",
    "        for target in ['train', 'dev', 'test']:\n",
    "            self.dataset[target] = TabularDataset(\n",
    "                path=dataset_path.format(target),\n",
    "                format='tsv',\n",
    "                fields=[('text', self.TEXT), ('label', self.LABEL)]\n",
    "            )\n",
    "            if use_vector:\n",
    "                self.TEXT.build_vocab(self.dataset[target], max_size=25000, vectors=vectors)\n",
    "            else:\n",
    "                self.TEXT.build_vocab(self.dataset[target], max_size=25000)\n",
    "\n",
    "            self.LABEL.build_vocab(self.dataset[target])\n",
    "            self.dataloader[target] = Iterator(self.dataset[target],\n",
    "                                               batch_size=batch_size,\n",
    "                                               device=pdevice,\n",
    "                                               repeat=False,\n",
    "                                               sort_key=lambda x: len(x.text),\n",
    "                                               shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  5, 296, 442,   2]]),tensor([1.])\n",
      "tensor([[  54,  346,  322,  145, 1570,    8,  140,    4, 4116,    7, 1240, 1830,\n",
      "          304,   37, 2749,    2]]),tensor([0.])\n",
      "tensor([[2562,    4,  374, 4440,   16,    4, 1292, 2042, 1136,   12, 2015,    8,\n",
      "         2510,    4,  495,  612,   16,  495,  612,  658]]),tensor([1.])\n",
      "tensor([[   4,  106,  292,    4,   19,    8,    5, 1450,  276,    2]]),tensor([1.])\n",
      "tensor([[  80,  101, 1088,  265,    8,  306,   36,    4, 1541,   76,    6,  259,\n",
      "           50,   31,  108,  151, 1901,   45,  258,    3,    6, 3827,   11, 1057,\n",
      "         4291,   12,  279,  263,  255,  356,   91,    8,  567,  664,    2]]),tensor([0.])\n",
      "tensor([[   5, 4723,  349,  224,   36,   21, 1866,  769, 1198,   58,   12, 1916,\n",
      "           23,  469,    6,    5, 1235,    8, 1652,   44,  301,    2]]),tensor([1.])\n",
      "tensor([[ 773,   37, 1420,    6,  581,   11, 3002,  106,    3,    4,   18,   11,\n",
      "          332, 1526,   13,   25,  607,    2,  118,   12,  305,    6,  751,    2]]),tensor([1.])\n",
      "tensor([[ 521,   10,    8, 1696,    3,  280, 1951,    3,    8,  249,    5,   75,\n",
      "            8, 2188, 1292, 4915,    8,    4, 4564,    7,    5,  394,    7,    4,\n",
      "          281,   14,   12, 3051,    8,  203, 2092, 3257,    6, 2501,  536, 4709,\n",
      "            7,    4,  807,   17,   10,  149,   40,   38,   88, 1229,  470,    2]]),tensor([1.])\n",
      "tensor([[ 438, 2201,  152,   22,   12, 1334,   19, 4105,    2]]),tensor([0.])\n",
      "tensor([[   5, 1275,    3,   15,   69,    9,  310,   18,   36,    5, 3389, 3663,\n",
      "         1181,   13, 3547,   79,    5,  210,   11,  146,    8, 4303,   44,  164,\n",
      "          352,    2]]),tensor([1.])\n",
      "tensor([[  21,  163,    9,  784,    6, 3059,   18,   36,    4,  252,  234,   23,\n",
      "          948,    8, 1195,   23,   42,   14,   12, 2045,   13,    4,  150,    2]]),tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# Sampling dataset format\n",
    "dataset = MyDataset(batch_size=1)\n",
    "for idx, v in enumerate(dataset.dataloader['test']):\n",
    "    print(f\"{v.text},{v.label}\")\n",
    "    if idx == 10:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "- Now you just select model, hyperparameter, structure, and so on like below\n",
    "- ref. [train.py](train.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(optim='adam', lr=0.001, batch_size=64, epoch=1, cuda=False, ed=300, word_vector=True, model='lstm_attn', hd=512, layer=2, bidirectional=True, dropout=True)\n",
      "Model: LSTM with Attension\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Optim: Adam\n",
      "Epoch: 01, Train Loss: 0.571, Train Acc: 69.81%, Val. Loss: 0.509, Val. Acc: 74.88%, Test Loss: 0.495, Test Acc: 75.49%\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p checkpoints\n",
    "!PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python python train.py \\\n",
    "    --optim=adam \\\n",
    "    --lr=1e-3 \\\n",
    "    --batch_size=64 \\\n",
    "    --epoch=15 \\\n",
    "    --ed=300 \\\n",
    "    --model=lstm_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you want realtime training inforamtion on tensorboard, just type like below and enter it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "- Finally, you can use your trainied model!\n",
    "- ref. [demo.py](demo.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'required' is an invalid argument for positionals",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     15\u001b[0m     parser \u001b[39m=\u001b[39m argparse\u001b[39m.\u001b[39mArgumentParser()\n\u001b[0;32m---> 16\u001b[0m     parser\u001b[39m.\u001b[39;49madd_argument(\u001b[39m'\u001b[39;49m\u001b[39mckpt_path\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m, required\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     17\u001b[0m     parser\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m, required\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m     get_model(args\u001b[39m.\u001b[39mckpt_path)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/argparse.py:1405\u001b[0m, in \u001b[0;36m_ActionsContainer.add_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mdest\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m   1404\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdest supplied twice for positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1405\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_positional_kwargs(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1407\u001b[0m \u001b[39m# otherwise, we're adding an optional argument\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1409\u001b[0m     kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_optional_kwargs(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/pytorch-sentiment-analysis-classification/lib/python3.9/argparse.py:1521\u001b[0m, in \u001b[0;36m_ActionsContainer._get_positional_kwargs\u001b[0;34m(self, dest, **kwargs)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mrequired\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m   1520\u001b[0m     msg \u001b[39m=\u001b[39m _(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrequired\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is an invalid argument for positionals\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1521\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m   1523\u001b[0m \u001b[39m# mark positional arguments as required if at least one is\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39m# always required\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mnargs\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [OPTIONAL, ZERO_OR_MORE]:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'required' is an invalid argument for positionals"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import spacy\n",
    "import argparse\n",
    "import re\n",
    "\n",
    "from dataset import MyDataset\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def get_models(ckpt_path, device, dataset):\n",
    "    from train import build_model\n",
    "    info = torch.load(ckpt_path)\n",
    "    args = info['args']\n",
    "    pth = info['pth']\n",
    "\n",
    "    model = build_model(args, device, dataset)\n",
    "    model.load_state_dict(pth)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--ckpt_path', type=str, required=True)\n",
    "    parser.add_argument('input', type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    dataset = MyDataset(batch_size=1, use_vector=True)\n",
    "    model = get_models(args.ckpt_path, device, dataset)\n",
    "\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(args.input)]\n",
    "    indexed = [dataset.TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    tensor = torch.cat(2*[tensor], dim=1)\n",
    "    preds = model(tensor)\n",
    "    max_preds = preds.argmax(dim=1)\n",
    "    print(max_preds[0].item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-sentiment-analysis-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
